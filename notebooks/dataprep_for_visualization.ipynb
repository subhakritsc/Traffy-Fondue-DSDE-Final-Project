{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tWOGXdlY3PGC"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H3bhONdJ1A_x"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Tt811-u-1Bkt"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "    !wget -q https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
        "    !tar xf spark-3.5.5-bin-hadoop3.tgz\n",
        "    !mv spark-3.5.5-bin-hadoop3 spark\n",
        "    !pip install -q findspark\n",
        "    import os\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    os.environ[\"SPARK_HOME\"] = \"/content/spark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_UgimjOw1Egf"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "spark_url = 'local'\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "spark = SparkSession.builder\\\n",
        "        .master(spark_url)\\\n",
        "        .appName('Spark')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsilw1hS4JAP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGf9uyjc1PFW",
        "outputId": "cca90163-42e3-4e76-f7fe-abf2ac9af5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Xbce69FUS1DOgRkOOmi6VT2eysYlSSFJ\n",
            "From (redirected): https://drive.google.com/uc?id=1Xbce69FUS1DOgRkOOmi6VT2eysYlSSFJ&confirm=t&uuid=01633e0f-2398-4371-9858-7702f9a32e65\n",
            "To: /content/df_with_cluster.csv\n",
            "100% 637M/637M [00:06<00:00, 103MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Loading File from Google Drive\n",
        "!gdown 'https://drive.google.com/uc?id=1PE-fNRsLA9qqEHmaiof0xV-Uz_5ZfCuO' --output df_with_cluster.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hm3C6jXOzJj1"
      },
      "outputs": [],
      "source": [
        "# -------------- TABLE 1: Showing Example Comment ---------------------\n",
        "\n",
        "# 1. Read the CSV\n",
        "df_with_clustering = spark.read.csv('df_with_cluster.csv', header=True, inferSchema=True)\n",
        "\n",
        "# 2. Select and rename\n",
        "df = df_with_clustering.select(\n",
        "    col('cluster_id').alias('cluster'),\n",
        "    col('comment')\n",
        ")\n",
        "\n",
        "# 3. Drop noise row\n",
        "df = df.filter(~col('cluster').startswith('noise'))\n",
        "\n",
        "# 4. Save the DataFrame as a single CSV file\n",
        "df.coalesce(1).write.csv('example_comment', header=True, mode='overwrite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epORc3yB_ZZA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcjZPjwG_YLq",
        "outputId": "06682600-383b-41f9-c4ad-305577a61c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=165cvX8TlwZrShLMBpvEg7v2iZgZlG8h-\n",
            "From (redirected): https://drive.google.com/uc?id=165cvX8TlwZrShLMBpvEg7v2iZgZlG8h-&confirm=t&uuid=4688ac35-407c-42fe-8485-8d7153d88c53\n",
            "To: /content/bright.csv\n",
            "100% 135M/135M [00:01<00:00, 133MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KupegXEIkR8hURDfWE7qGM9HRlWY-iCT\n",
            "To: /content/piti.csv\n",
            "100% 4.10M/4.10M [00:00<00:00, 196MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 'https://drive.google.com/uc?id=12RR873XXJrFnJiKJWkqYNnzAfUB-sDyL' --output bright.csv\n",
        "!gdown 'https://drive.google.com/uc?id=1KupegXEIkR8hURDfWE7qGM9HRlWY-iCT' --output piti.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOnhF30gzU16",
        "outputId": "7e0593ae-275f-47e1-ae40-b296a04840b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w21nVLe-xYaQ3ZiP5nOY_f9R_t9dMbII\n",
            "To: /content/knn.pkl\n",
            "100% 23.9M/23.9M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "# -------------- TABLE 2: Map and Graph visualization ---------------------\n",
        "\n",
        "# 1. piti: 'cluster_id', 'num_times', 'status'\n",
        "# 2. bright: 'cluster_id', 'cluster_desc', 'lat', 'long', 'organization'\n",
        "# 3. keen: zone scraping to get 'zone'\n",
        "\n",
        "# 1. Load the pre-trained KNN model from Google Drive\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1w21nVLe-xYaQ3ZiP5nOY_f9R_t9dMbII/view?usp=drive_link\"\n",
        "\n",
        "with open(\"knn.pkl\", \"rb\") as f:\n",
        "    knn = pickle.load(f)\n",
        "\n",
        "# 2. Read the CSV\n",
        "piti_df = spark.read.csv('piti.csv', header=True, inferSchema=True)\n",
        "bright_df = spark.read.csv('bright.csv', header=True, inferSchema=True)\n",
        "bright_df = bright_df.withColumnRenamed(\"lon\", \"long\")\n",
        "\n",
        "# 3. Merge the tables on 'cluster_id'\n",
        "piti_df = piti_df.withColumn(\"cluster_id\", col(\"cluster_id\").cast(\"string\"))\n",
        "bright_df = bright_df.withColumn(\"cluster_id\", col(\"cluster_id\").cast(\"string\"))\n",
        "merged_df = piti_df.join(bright_df, on='cluster_id', how='inner')\n",
        "\n",
        "# 4. Define the pandas_udf function to apply the KNN model and predict the zone\n",
        "@pandas_udf(StringType())\n",
        "def predict_zone_pandas_udf(lat: pd.Series, lon: pd.Series) -> pd.Series:\n",
        "    # Assuming knn is already loaded with pickle\n",
        "    coords = np.column_stack((lat.values, lon.values))  # Combine lat and lon into a 2D array\n",
        "    return pd.Series(knn.predict(coords))\n",
        "\n",
        "# 5. Apply the pandas_udf function to predict the zone based on latitude and longitude\n",
        "merged_df = merged_df.withColumn('zone', predict_zone_pandas_udf(col('lat'), col('long')))\n",
        "\n",
        "# 6. Save the DataFrame as a single CSV file\n",
        "merged_df.coalesce(1).write.csv('cluster_data', header=True, mode='overwrite')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
